{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940c8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "#from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D\n",
    "from denoising_diffusion_pytorch import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.stats import skew,kurtosis\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab4655-05b8-431d-b91c-19a4e350f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision numpy matplotlib einops ema_pytorch accelerate pytorch_fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea443434-8f88-4dd4-bcb2-23ab471445a6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d09d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_testsub = 32\n",
    "num_classes = 4\n",
    "num_channel = 40\n",
    "num_datapoints = 8064\n",
    "num_trials = 40\n",
    "sampling_rate = 128 # 128Hz as given in the data\n",
    "\n",
    "def loadfiles_normalized():\n",
    "    data_dict = {}\n",
    "    print(\"Loading files into data_dict .................\")\n",
    "    for i in range(num_testsub):\n",
    "                    if i < 10:\n",
    "                        name = '%0*d' % (2,i+1)\n",
    "                    else:\n",
    "                        name = i+1\n",
    "                    fname = 'data/noramlized_datasub'+str(name) +'.npy'\n",
    "                    data_dict[\"sub%s\" %name] = np.load(fname)    \n",
    "    print(\"Loaded!!!!!\") \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1d4b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files into data_dict .................\n",
      "Loaded!!!!!\n"
     ]
    }
   ],
   "source": [
    "data = loadfiles_normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7447258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 99)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (40, 40, 99) (videonumber/trialnumber , channelnumber, datapoints)\n",
    "data['sub01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b10e18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 99)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix 1\n",
    "data['sub01'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b23af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((1280,3,40,104))\n",
    "matrix[:] = np.nan\n",
    "counter = 0\n",
    "check = np.zeros((104,40))\n",
    "for sub in data.keys():\n",
    "    for i in range(data[sub][0].shape[0]):\n",
    "        temp = data[sub][i]\n",
    "#        print(temp.shape)\n",
    "#        temp = temp[: , :96]\n",
    "        # pad the array with a column of zeros\n",
    "        temp = np.pad(temp, ((0, 0), (0, 5)), mode='constant')\n",
    "        check = temp\n",
    "        matrix[counter, :] = temp\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad865281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 3, 40, 104)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be1ce8e6-c107-4d2c-aa0b-99b1e0861fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34193571, 0.80623188, 0.06811771, 0.90654791, 0.09854338,\n",
       "       0.04772348, 0.08286564, 0.15040094, 0.30077994, 0.65387255,\n",
       "       0.69462309, 0.06582711, 0.90572575, 0.14277261, 0.08427975,\n",
       "       0.08188165, 0.89104112, 0.01714881, 0.57187982, 0.41246195,\n",
       "       0.04185219, 0.75087426, 0.09848531, 0.05350247, 0.13487976,\n",
       "       0.36188846, 0.36149486, 0.53913732, 0.39823617, 0.03155432,\n",
       "       0.98171454, 0.05919493, 0.03148297, 0.02311594, 0.71712978,\n",
       "       0.02135819, 0.46509931, 0.5838429 , 0.08874375, 0.82108996,\n",
       "       0.06263677, 0.03374082, 0.12594113, 0.32879547, 0.3429113 ,\n",
       "       0.5032681 , 0.483895  , 0.02954557, 0.96045352, 0.04326873,\n",
       "       0.01980131, 0.01610539, 0.87665463, 0.02988822, 0.36464224,\n",
       "       0.38449448, 0.35547156, 0.77140733, 0.11058201, 0.06742717,\n",
       "       0.26676349, 0.6188545 , 0.10892795, 0.66521184, 0.22899971,\n",
       "       0.0921358 , 0.90980782, 0.04263698, 0.02005452, 0.06971488,\n",
       "       0.37799671, 0.15096301, 0.51746719, 0.15454107, 0.05629756,\n",
       "       0.94213308, 0.06538389, 0.03058009, 0.05711159, 0.42271161,\n",
       "       0.12928563, 0.48094057, 0.19853031, 0.11789539, 0.89084038,\n",
       "       0.08848318, 0.0431896 , 0.09493367, 0.3444608 , 0.19505668,\n",
       "       0.52837727, 0.3082886 , 0.05501264, 0.9295055 , 0.04626059,\n",
       "       0.02578249, 0.05137255, 0.67887759, 0.05480701, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09084158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(matrix).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2535404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29633097, 0.5152931 , 0.05009588, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.540126  , 0.55177657, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55221434, 0.31579877, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.34482342, 0.46382535, 0.1260563 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.90617533, 0.94400325, 0.67083414, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35146873, 0.27318548, 0.20812183, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878dccdb-274c-4f4c-876b-06de9a8ff208",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_matrix = torch.tensor(matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb757be-b2ce-42a4-b512-b11c01462715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 3, 40, 104])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d43ac0d9-1b9e-4b46-bf1b-43cbf3d82aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 3, 40, 104)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f81a28e1-aeb5-4303-bcc1-d7093a257a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images\n",
    "for i in range(1280):\n",
    "    transpose = np.transpose(matrix[i,:,:,:], (1,2,0))\n",
    "    tra = np.multiply(transpose, 255).astype(np.uint8)\n",
    "    img = Image.fromarray(tra)\n",
    "    img.save(\"images/train\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bc728-0c98-4392-8680-f2f190f34e71",
   "metadata": {},
   "source": [
    "### PNG and JPEG comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a7542-0b26-45ed-9c7c-80bc942b0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('train20.jpeg')\n",
    "print(test.shape)\n",
    "test = np.transpose(test, (2,0,1))\n",
    "test = np.multiply(test,1/255)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64009844-bd93-4907-a33c-b7e95e601fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 40, 104)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.29411765, 0.51372549, 0.04705882, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.5372549 , 0.54901961, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.54901961, 0.31372549, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.34117647, 0.4627451 , 0.1254902 , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.90588235, 0.94117647, 0.67058824, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.34901961, 0.27058824, 0.20784314, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.29411765, 0.51372549, 0.04705882, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.5372549 , 0.54901961, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.54901961, 0.31372549, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.34117647, 0.4627451 , 0.1254902 , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.90588235, 0.94117647, 0.67058824, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.34901961, 0.27058824, 0.20784314, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.29411765, 0.51372549, 0.04705882, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.5372549 , 0.54901961, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.54901961, 0.31372549, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.34117647, 0.4627451 , 0.1254902 , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.90588235, 0.94117647, 0.67058824, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.34901961, 0.27058824, 0.20784314, ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = cv2.imread('train20.png')\n",
    "print(test.shape)\n",
    "test2 = np.transpose(test2, (2,0,1))\n",
    "test2 = np.multiply(test2,1/255)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b265359-94af-4679-a1fb-5e13360c732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(fo, test2, rtol=0.1, atol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2006df4-6f49-41f8-b1d7-a3fc21ff269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(fo,np.multiply(test,(1/255)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684f2ab-8be0-4496-bf2a-593e64cee780",
   "metadata": {},
   "source": [
    "For two images the png format was closer to the original input with a tolerance of 0.1 which failed in the case of jpeg. Therefore, png will be used to store the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef6509a7-f007-4e02-bcf6-a7b92256c079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748f72078ca64f928d4da83b740a1c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "# 33 min for 50 train_num_steps\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8)\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = (40,104),\n",
    "    timesteps = 1000,   # number of steps\n",
    "    loss_type = 'l1'    # L1 or L2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    'images/',\n",
    "    train_batch_size = 32,\n",
    "    train_lr = 8e-5,\n",
    "    train_num_steps = 50,#700000,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = True,                       # turn on mixed precision\n",
    "    calculate_fid = True              # whether to calculate fid during training\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4a96fbb-a760-422e-a474-68dcd60cf159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0f94f6092c40f3bcb67d6c85fced3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_images = diffusion.sample(batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f2f66d2-9a25-4101-aa29-52ef7a9e35e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40, 104])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e4dd32c2ff469caeb8aec48aeaea7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "# 880 images needs 880 / 3 layers = 294 \n",
    "# 294 images needed into 10 chunks --> 30 images per loop\n",
    "\n",
    "# Reconstruct Dataset\n",
    "# 1280 images needs 1280 / 3 layers = 427\n",
    "# 427 images needed into 10 chunks --> 43 images per loop\n",
    "\n",
    "for i in range(10):\n",
    "    sampled_images = diffusion.sample(batch_size = 43)\n",
    "    torch.save(sampled_images,'sampledT_40-104_43_'+str(i))\n",
    "    print(\"Finished Sample: \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02ee3202-1f4e-4f56-a8e6-b0dab68118a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sampled_images)\n",
    "torch.save(sampled_images,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174573e6-5c94-4cdb-93c0-3e24b2569be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([427, 3, 40, 104])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.load('test')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b1be548-11ad-4d1c-a5e2-90abb8398503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 40, 104])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test02 = torch.load(\"sampled_test0\")\n",
    "test02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842dc787-6c13-4923-a579-8370c04b0dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
