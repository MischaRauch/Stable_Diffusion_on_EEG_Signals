{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de3d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:31:34.204196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout,Activation,MaxPooling2D,ReLU,Add,GlobalAvgPool2D\n",
    "from tensorflow.keras import Model,Sequential\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1a9e5",
   "metadata": {},
   "source": [
    "## Get the Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd294699",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_testsub = 32\n",
    "num_classes = 4\n",
    "num_channel = 32\n",
    "num_datapoints = 8064\n",
    "num_trials = 40\n",
    "sampling_rate = 128 # 128Hz as given in the data\n",
    "\n",
    "def loadfiles_normalized():\n",
    "    data_dict = {}\n",
    "    print(\"Loading files into data_dict .................\")\n",
    "    for i in range(num_testsub):\n",
    "                    if i < 10:\n",
    "                        name = '%0*d' % (2,i+1)\n",
    "                    else:\n",
    "                        name = i+1\n",
    "                    fname = 'data/data_prepared/data_norm_stft/noramlized_datasub'+str(name) +'.npy'\n",
    "                    data_dict[\"sub%s\" %name] = np.load(fname)    \n",
    "    print(\"Loaded!!!!!\") \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6ef58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files into data_dict .................\n",
      "Loaded!!!!!\n"
     ]
    }
   ],
   "source": [
    "data_dict = loadfiles_normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb0a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = np.load('data/data_prepared/labels/label_class_0.npy')\n",
    "arousal = np.load('data/data_prepared/labels/label_class_1.npy')\n",
    "dominance = np.load('data/data_prepared/labels/label_class_2.npy')\n",
    "liking = np.load('data/data_prepared/labels/label_class_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ce49b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e4ff9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 32, 44)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['sub01'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26acff",
   "metadata": {},
   "source": [
    "## Create train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09073674",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c313de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with 22 participants each has 40 videos = 880\n",
    "train = np.zeros((0,32,44))\n",
    "train[:] = np.nan\n",
    "#train1 = \n",
    "test = np.zeros((0,32,44))\n",
    "test[:] = np.nan\n",
    "\n",
    "participation_counter = 0\n",
    "for sub in data_dict.keys():\n",
    "    if participation_counter < 22:\n",
    "        train = np.concatenate((train, data_dict[sub]), axis=0)\n",
    "    else:\n",
    "        test = np.concatenate((test, data_dict[sub]), axis=0)\n",
    "    participation_counter = participation_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c5f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "488de44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cbf605a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 32, 44)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b29b704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 32, 44)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0077769",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd82f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val22 = valence[: 880]\n",
    "aro22 = arousal[: 880]\n",
    "dom22 = dominance[: 880]\n",
    "lik22 = liking[: 880]\n",
    "\n",
    "y_test_va = valence[880: ]\n",
    "y_test_ar = arousal[880: ]\n",
    "y_test_do = dominance[880: ]\n",
    "y_test_li = liking[880: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962ec17",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0592052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 1408)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reshape(-1, 32*44).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59b892c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN based model for actual/original dataset\n",
    "def knnmodel(xtrain,ytrain,xtest,ytest,kval):\n",
    "  random_state=100\n",
    "  # print(\"xtrain.shape,ytrain.shape\",xtrain.shape,ytrain.shape)\n",
    "  # print(\"xtest.shape,ytest.shape\",xtrain.shape,ytrain.shape)\n",
    "  # Define the KNN model here\n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=kval) \n",
    "  model.fit(xtrain, ytrain)\n",
    "  y_pred = model.predict(xtest)\n",
    "\n",
    "  # print(\"Accuracy score for fold\",fold_no)\n",
    "  acc = accuracy_score(ytest, y_pred)*100\n",
    "  #acc = round(acc, 4)\n",
    "  print(\"Accuracy\",acc)\n",
    "  # print(classification_report(ytest, y_pred))\n",
    "  # print(confusion_matrix(ytest,y_pred))\n",
    "  # return acc,xtrain, xtest, ytrain, ytest\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2464b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN based model for augmented data\n",
    "def knnmodel2(xtrain,ytrain,xtest,ytest,kval):\n",
    "  \n",
    "  # print(\"xtrain.shape,ytrain.shape\",xtrain.shape,ytrain.shape)\n",
    "  # print(\"xtest.shape,ytest.shape\",xtest.shape,ytest.shape)\n",
    "\n",
    "  # Define the KNN model here\n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=kval)\n",
    "  model.fit(xtrain, ytrain)\n",
    "  y_pred = model.predict(xtest)\n",
    "\n",
    "  # print(\"Accuracy score for fold\",fold_no)\n",
    "  acc = accuracy_score(ytest, y_pred)*100\n",
    "  #acc = round(acc, 4)\n",
    "  print(\"Accuracy\",acc)\n",
    "  #print(classification_report(ytest, y_pred))\n",
    "  #print(confusion_matrix(ytest,y_pred))\n",
    "  # return acc,xtrain, xtest, ytrain, ytest\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd50f1c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value = 1\n",
      "######################################### Valence #########################################\n",
      "Accuracy 49.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 48.5\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 53.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 53.5\n",
      "K value = 2\n",
      "######################################### Valence #########################################\n",
      "Accuracy 42.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 44.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 41.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 47.75\n",
      "K value = 3\n",
      "######################################### Valence #########################################\n",
      "Accuracy 48.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 46.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 53.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 54.0\n",
      "K value = 4\n",
      "######################################### Valence #########################################\n",
      "Accuracy 46.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 44.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 43.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 51.74999999999999\n",
      "K value = 5\n",
      "######################################### Valence #########################################\n",
      "Accuracy 50.5\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.74999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 54.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 57.49999999999999\n",
      "K value = 6\n",
      "######################################### Valence #########################################\n",
      "Accuracy 48.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 47.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 46.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 55.00000000000001\n",
      "K value = 7\n",
      "######################################### Valence #########################################\n",
      "Accuracy 52.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 48.25\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 53.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 59.0\n",
      "K value = 8\n",
      "######################################### Valence #########################################\n",
      "Accuracy 51.74999999999999\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 49.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 48.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 56.49999999999999\n",
      "K value = 9\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.24999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 54.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.25\n",
      "K value = 10\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 51.24999999999999\n",
      "######################################### Liking #########################################\n",
      "Accuracy 59.25\n",
      "K value = 11\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 57.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 59.5\n",
      "K value = 12\n",
      "######################################### Valence #########################################\n",
      "Accuracy 50.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.24999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 52.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 56.99999999999999\n",
      "K value = 13\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.74999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 58.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.0\n",
      "K value = 14\n",
      "######################################### Valence #########################################\n",
      "Accuracy 50.5\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Liking #########################################\n",
      "Accuracy 56.49999999999999\n",
      "K value = 15\n",
      "######################################### Valence #########################################\n",
      "Accuracy 51.5\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 60.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.25\n",
      "K value = 16\n",
      "######################################### Valence #########################################\n",
      "Accuracy 50.74999999999999\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 53.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 57.49999999999999\n",
      "K value = 17\n",
      "######################################### Valence #########################################\n",
      "Accuracy 51.74999999999999\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.74999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 59.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.25\n",
      "K value = 18\n",
      "######################################### Valence #########################################\n",
      "Accuracy 49.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 59.0\n",
      "K value = 19\n",
      "######################################### Valence #########################################\n",
      "Accuracy 51.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.24999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 61.75000000000001\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 20\n",
      "######################################### Valence #########################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 49.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.74999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 60.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.0\n",
      "K value = 21\n",
      "######################################### Valence #########################################\n",
      "Accuracy 52.5\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.24999999999999\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 63.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 22\n",
      "######################################### Valence #########################################\n",
      "Accuracy 49.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 60.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.75000000000001\n",
      "K value = 23\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 50.5\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 65.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.0\n",
      "K value = 24\n",
      "######################################### Valence #########################################\n",
      "Accuracy 50.5\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 53.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 60.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 60.5\n",
      "K value = 25\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.25\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 64.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.75000000000001\n",
      "K value = 26\n",
      "######################################### Valence #########################################\n",
      "Accuracy 51.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 61.75000000000001\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 27\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 53.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 66.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 28\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 51.5\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 64.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.0\n",
      "K value = 29\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 65.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 30\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 53.5\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 63.24999999999999\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.75000000000001\n",
      "K value = 31\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.25\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 67.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.5\n",
      "K value = 32\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 64.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.25000000000001\n",
      "K value = 33\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 53.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 34\n",
      "######################################### Valence #########################################\n",
      "Accuracy 56.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 52.5\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 64.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 61.75000000000001\n",
      "K value = 35\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 66.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 36\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 63.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 37\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 66.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 38\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 65.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.0\n",
      "K value = 39\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.0\n",
      "######################################### Arousal #########################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 55.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 40\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 64.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.0\n",
      "K value = 41\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.00000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 42\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 66.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 43\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 44\n",
      "######################################### Valence #########################################\n",
      "Accuracy 56.49999999999999\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 65.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 45\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 46\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 68.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.25000000000001\n",
      "K value = 47\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.00000000000001\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.50000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 69.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 48\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.00000000000001\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 67.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "K value = 49\n",
      "######################################### Valence #########################################\n",
      "Accuracy 54.75\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 67.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n"
     ]
    }
   ],
   "source": [
    "trainlabel_list = [val22, aro22, dom22, lik22]\n",
    "testlabel_list = [y_test_va, y_test_ar, y_test_do, y_test_li]\n",
    "names = [\"Valence\",\"Arousal\",\"Dominance\",\"Liking\"]\n",
    "scorelist = []\n",
    "score = []\n",
    "\n",
    "\n",
    "for k in range(1,50):\n",
    "  print(\"K value =\",k)\n",
    "  for traain,tesst,name in zip(trainlabel_list,testlabel_list,names):\n",
    "    print(\"#########################################\",name,\"#########################################\")\n",
    "    sc = knnmodel2(train.reshape(-1, 32*44),traain,test.reshape(-1, 32*44),tesst,kval = k)\n",
    "    scorelist.append((sc,k))\n",
    "    score.append(sc)\n",
    "  \n",
    "max_va = (0,0)\n",
    "max_ar = (0,0)\n",
    "max_do = (0,0)\n",
    "max_li = (0,0)\n",
    "j = 0\n",
    "for i in range(int(len(scorelist)/4)):\n",
    "    if scorelist[j][0] > max_va[0]:\n",
    "        max_va = scorelist[j]\n",
    "    if scorelist[j+1][0] > max_ar[0]:\n",
    "        max_ar = scorelist[j+1]\n",
    "    if scorelist[j+2][0] > max_do[0]:\n",
    "        max_do = scorelist[j+2]\n",
    "    if scorelist[j+3][0] > max_li[0]:\n",
    "        max_li = scorelist[j+3]\n",
    "    j = j+4\n",
    "\n",
    "#for i,name in zip(scorelist,names):\n",
    "#    print (\"Accuracy of \",name ,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caee934",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9cfaa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56.49999999999999, 44)\n",
      "(56.75, 43)\n",
      "(69.75, 47)\n",
      "(62.5, 33)\n"
     ]
    }
   ],
   "source": [
    "print(max_va)\n",
    "print(max_ar)\n",
    "print(max_do)\n",
    "print(max_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50593e",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350976d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM based model for augmented data\n",
    "def svmmodel(xtrain,ytrain,xtest,ytest,c,kernel = 'linear'):\n",
    "\n",
    "  # SVM model\n",
    "\n",
    "  model = SVC(C=c,kernel=kernel,gamma = 'auto')\n",
    "  model.fit(xtrain, ytrain)\n",
    "  y_pred = model.predict(xtest)\n",
    "\n",
    "  # print(\"Accuracy score for fold\",fold_no)\n",
    "  acc = accuracy_score(ytest, y_pred)*100\n",
    "  acc = round(acc, 4)\n",
    "  print(\"Accuracy\",acc)\n",
    "  # print(classification_report(ytest, y_pred))\n",
    "  # print(confusion_matrix(ytest,y_pred))\n",
    "  # return acc,xtrain, xtest, ytrain, ytest\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72b11151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "C value = 0.0001\n",
      "######################################### Valence #########################################\n",
      "Accuracy 59.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 73.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "\n",
      "\n",
      "C value = 0.001\n",
      "######################################### Valence #########################################\n",
      "Accuracy 56.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 73.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "\n",
      "\n",
      "C value = 0.01\n",
      "######################################### Valence #########################################\n",
      "Accuracy 55.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.75\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 67.75\n",
      "######################################### Liking #########################################\n",
      "Accuracy 62.5\n",
      "\n",
      "\n",
      "C value = 0.1\n",
      "######################################### Valence #########################################\n",
      "Accuracy 53.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.25\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 59.0\n",
      "######################################### Liking #########################################\n",
      "Accuracy 59.25\n",
      "\n",
      "\n",
      "C value = 1\n",
      "######################################### Valence #########################################\n",
      "Accuracy 56.25\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 56.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 60.25\n",
      "######################################### Liking #########################################\n",
      "Accuracy 55.0\n",
      "\n",
      "\n",
      "C value = 10\n",
      "######################################### Valence #########################################\n",
      "Accuracy 58.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 61.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 53.0\n",
      "\n",
      "\n",
      "C value = 100\n",
      "######################################### Valence #########################################\n",
      "Accuracy 58.0\n",
      "######################################### Arousal #########################################\n",
      "Accuracy 55.0\n",
      "######################################### Dominance #########################################\n",
      "Accuracy 61.5\n",
      "######################################### Liking #########################################\n",
      "Accuracy 53.0\n"
     ]
    }
   ],
   "source": [
    "# Using actual data\n",
    "trainlabel_list = [val22, aro22, dom22, lik22]\n",
    "testlabel_list = [y_test_va, y_test_ar, y_test_do, y_test_li]\n",
    "names = [\"Valence\",\"Arousal\",\"Dominance\",\"Liking\"]\n",
    "scorelist = []\n",
    "cval = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "for c in cval:\n",
    "  print(\"\\n\")\n",
    "  print(\"C value =\",c)\n",
    "  for traain,tesst,name in zip(trainlabel_list,testlabel_list,names):\n",
    "    print(\"#########################################\",name,\"#########################################\")\n",
    "    sc = svmmodel(train.reshape(-1, 32*44),traain,test.reshape(-1, 32*44),tesst,c = c)\n",
    "    scorelist.append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ca7f7",
   "metadata": {},
   "source": [
    "Best results <br>\n",
    "Accuracy of  Valence 59.25 <br>\n",
    "Accuracy of  Arousal 56.25 <br>\n",
    "Accuracy of  Dominance 73.0 <br>\n",
    "Accuracy of  Liking 62.50 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc37c3d",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c26fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "def deepmodel(modelnum,xtrain,ytrain,xtest,ytest,nepochs,batch_size):\n",
    "  # ()\n",
    "  \n",
    "  ytrain = to_categorical(ytrain)\n",
    "  ytest = to_categorical(ytest)\n",
    "\n",
    "\n",
    "\n",
    "  input_shape = (32, 44, 1)\n",
    "  # print(xtrain.shape,xtest.shape)\n",
    "  xtrain = np.reshape(xtrain,[-1, 32, 44, 1])\n",
    "  xtest = np.reshape(xtest,[-1, 32, 44, 1])\n",
    "  print(\"xtrain.shape,ytrain.shape\")\n",
    "  print(xtrain.shape,ytrain.shape)\n",
    "  if modelnum == 1:\n",
    "  # Model 1\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "  elif modelnum == 2:\n",
    "    # Resnet kind of model\n",
    "\n",
    "    def conv_bn_relu(x, filters, kernel_size, strides):\n",
    "        x = Conv2D(filters=filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def identity_block(tensor, filters):\n",
    "        x = conv_bn_relu(tensor, filters=filters, kernel_size=1, strides=1)\n",
    "        x = conv_bn_relu(x, filters=filters, kernel_size=3, strides=1)\n",
    "        x = Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)  # notice: filters=4*filters\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Add()([x, tensor])\n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def projection_block(tensor, filters, strides):\n",
    "        # left branch\n",
    "        x = conv_bn_relu(tensor, filters=filters, kernel_size=1, strides=1)\n",
    "        x = conv_bn_relu(x, filters=filters, kernel_size=3, strides=strides)\n",
    "        x = Conv2D(filters=4*filters, kernel_size=1, strides=1)(x)  # notice: filters=4*filters\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # right branch\n",
    "        shortcut = Conv2D(filters=4*filters, kernel_size=1, strides=strides)(tensor)  # notice: filters=4*filters\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "        x = Add()([x, shortcut])\n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def resnet_block(x, filters, reps, strides):\n",
    "        x = projection_block(x, filters=filters, strides=strides)\n",
    "        for _ in range(reps-1):  # the -1 is because the first block was a Conv one\n",
    "            x = identity_block(x, filters=filters)\n",
    "        return x\n",
    "\n",
    "\n",
    "    input = Input(shape=(32, 44, 1))\n",
    "\n",
    "    x = conv_bn_relu(input, filters=64, kernel_size=7, strides=2)  # [3]: 7x7, 64, strides 2\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)  # [3]: 3x3 max mool, strides 2\n",
    "\n",
    "    x = resnet_block(x, filters=64, reps=3, strides=1)\n",
    "    x = resnet_block(x, filters=128, reps=4, strides=2)  # s=2 ([2]: conv3_1)\n",
    "    x = resnet_block(x, filters=256, reps=6, strides=2)  # s=2 ([2]: conv4_1)\n",
    "    x = resnet_block(x, filters=512, reps=3, strides=2)  # s=2 ([2]: conv5_1)\n",
    "\n",
    "    x = GlobalAvgPool2D()(x)  # [3]: average pool *it is not written any pool size so we use Global\n",
    "\n",
    "    # # output = Dense(1, activation='sigmoid')(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    model = Model(input, output)\n",
    "\n",
    "\n",
    "\n",
    "  model.compile(loss= 'categorical_crossentropy',#'binary_crossentropy','categorical_crossentropy'\n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "  # Fit data to model\n",
    "  history = model.fit(xtrain,ytrain ,\n",
    "            batch_size = batch_size,\n",
    "            epochs=nepochs,\n",
    "            verbose=1)\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model.evaluate(xtest, ytest, verbose=0)#verbose =1 \n",
    "  y_pred = model.predict(xtest)\n",
    "  #     print(\"Fold number\",fold_no)\n",
    "  acc = scores[1]*100\n",
    "  acc = round(acc, 4)\n",
    "  print(\"Accuracy\",acc)\n",
    "  print(\"Loss\",scores[0])\n",
    "  # print(classification_report(ytest.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "  # print(confusion_matrix(ytest.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2cfce",
   "metadata": {},
   "source": [
    "## Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de29caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################### Valence #########################################\n",
      "xtrain.shape,ytrain.shape\n",
      "(880, 32, 44, 1) (880, 2)\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 27ms/step - loss: 0.6980 - accuracy: 0.5295\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6880 - accuracy: 0.5352\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6774 - accuracy: 0.5591\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6655 - accuracy: 0.6068\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6457 - accuracy: 0.6534\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.6293 - accuracy: 0.6534\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5936 - accuracy: 0.6818\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.5522 - accuracy: 0.7216\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4905 - accuracy: 0.7625\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4345 - accuracy: 0.7989\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3342 - accuracy: 0.8659\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3120 - accuracy: 0.8636\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.2392 - accuracy: 0.9034\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1692 - accuracy: 0.9432\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1143 - accuracy: 0.9568\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0820 - accuracy: 0.9739\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0424 - accuracy: 0.9932\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0247 - accuracy: 0.9955\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.9411e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.8745e-04 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.0001e-04 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.3149e-04 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.6933e-04 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.0981e-04 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.7438e-04 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.2982e-04 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9842e-04 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.6961e-04 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.4328e-04 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.1818e-04 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.9534e-04 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.7808e-04 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.6184e-04 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.4473e-04 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.3174e-04 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1670e-04 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.0544e-04 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.9395e-04 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.8437e-04 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.7472e-04 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6516e-04 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5839e-04 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5009e-04 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.4254e-04 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3618e-04 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2955e-04 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2349e-04 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1907e-04 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1330e-04 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.0959e-04 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.0486e-04 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.9771e-05 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.5833e-05 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 9.1650e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 8.8829e-05 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 8.6468e-05 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.2096e-05 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 7.8928e-05 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 7.5520e-05 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 7.3072e-05 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 7.0416e-05 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.7515e-05 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.5454e-05 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.2782e-05 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.1034e-05 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.8829e-05 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 5.6927e-05 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.4952e-05 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.3269e-05 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.1657e-05 - accuracy: 1.0000\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 4.9977e-05 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.8720e-05 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.6900e-05 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.5520e-05 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.3826e-05 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.2551e-05 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.1294e-05 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 4.0094e-05 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.8993e-05 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.7805e-05 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.6734e-05 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.5650e-05 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.4712e-05 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.3739e-05 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.2728e-05 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.1884e-05 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.1126e-05 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.0028e-05 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.9254e-05 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.8488e-05 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.7685e-05 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.7114e-05 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.6235e-05 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.5576e-05 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.4885e-05 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.4211e-05 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.3609e-05 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.3013e-05 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.2435e-05 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.1893e-05 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.1370e-05 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.0798e-05 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.0252e-05 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.9797e-05 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.9254e-05 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.8802e-05 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.8299e-05 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.7932e-05 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.7427e-05 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.7114e-05 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6623e-05 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6238e-05 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.5871e-05 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5472e-05 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5094e-05 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4757e-05 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4411e-05 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4099e-05 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.3780e-05 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3497e-05 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3131e-05 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2857e-05 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2553e-05 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2263e-05 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2018e-05 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1772e-05 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1526e-05 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1250e-05 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.0981e-05 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.0737e-05 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.0505e-05 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.0295e-05 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.0072e-05 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.8676e-06 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.6512e-06 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.4274e-06 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.2479e-06 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.0602e-06 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.8590e-06 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.6897e-06 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.4748e-06 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 8.3121e-06 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.1421e-06 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.9815e-06 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.8051e-06 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.6409e-06 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.4814e-06 - accuracy: 1.0000\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 29ms/step - loss: 7.3282e-06 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 7.1890e-06 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.0319e-06 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.8962e-06 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.7482e-06 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.6080e-06 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.4838e-06 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.3647e-06 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.2420e-06 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.1015e-06 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.9898e-06 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.8784e-06 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.7525e-06 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.6287e-06 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.5219e-06 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.4152e-06 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.3362e-06 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 5.1972e-06 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 5.1045e-06 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.9940e-06 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.9148e-06 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.8126e-06 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.7128e-06 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.6230e-06 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.5540e-06 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.4447e-06 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.3626e-06 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.2812e-06 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.1974e-06 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.1231e-06 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.0450e-06 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.9634e-06 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.8843e-06 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.8143e-06 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.7400e-06 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.6697e-06 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.6071e-06 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 3.5317e-06 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.4673e-06 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.4031e-06 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.3366e-06 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.2851e-06 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.2213e-06 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.1663e-06 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 3.1017e-06 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.0431e-06 - accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "Accuracy 51.75\n",
      "Loss 4.410883903503418\n",
      "######################################### Arousal #########################################\n",
      "xtrain.shape,ytrain.shape\n",
      "(880, 32, 44, 1) (880, 2)\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 30ms/step - loss: 0.6929 - accuracy: 0.5500\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6807 - accuracy: 0.5670\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.6857 - accuracy: 0.5830\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6765 - accuracy: 0.5852\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6628 - accuracy: 0.6011\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.6406 - accuracy: 0.6511\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6649 - accuracy: 0.6307\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6140 - accuracy: 0.6716\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.6027 - accuracy: 0.6943\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.5664 - accuracy: 0.7284\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.4938 - accuracy: 0.7875\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4436 - accuracy: 0.8068\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.3778 - accuracy: 0.8330\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.2835 - accuracy: 0.8841\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2381 - accuracy: 0.9136\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1492 - accuracy: 0.9432\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1177 - accuracy: 0.9534\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1007 - accuracy: 0.9648\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0504 - accuracy: 0.9864\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0362 - accuracy: 0.9943\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.8983e-04 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.6997e-04 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.7363e-04 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.0858e-04 - accuracy: 1.0000\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 5.5012e-04 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.0366e-04 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.5857e-04 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.1886e-04 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.8507e-04 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.5708e-04 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.3477e-04 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.1056e-04 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.8950e-04 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.7434e-04 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.5446e-04 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.4025e-04 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.2869e-04 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1651e-04 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.0312e-04 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.9484e-04 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.8224e-04 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.7304e-04 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.6527e-04 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5671e-04 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4915e-04 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.4216e-04 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3588e-04 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.2972e-04 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2409e-04 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1914e-04 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1414e-04 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.0888e-04 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0427e-04 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.0047e-04 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.5740e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.2004e-05 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.8406e-05 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.4950e-05 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.1466e-05 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.8698e-05 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.5595e-05 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.2615e-05 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.9690e-05 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.7289e-05 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 6.4919e-05 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.2216e-05 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.9909e-05 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.7701e-05 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 5.5632e-05 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.3719e-05 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.1876e-05 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.9909e-05 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.7948e-05 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 4.6229e-05 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.4648e-05 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.2995e-05 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.1447e-05 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9992e-05 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.8650e-05 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.7180e-05 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.5918e-05 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.4567e-05 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.3558e-05 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.2224e-05 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.1057e-05 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.0117e-05 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.9045e-05 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.7870e-05 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.6857e-05 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.5886e-05 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.4998e-05 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.4117e-05 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.3296e-05 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.2492e-05 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.1727e-05 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.0930e-05 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.0310e-05 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.9577e-05 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.8854e-05 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.8284e-05 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.7574e-05 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6986e-05 - accuracy: 1.0000\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6441e-05 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5842e-05 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5290e-05 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4766e-05 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.4298e-05 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3790e-05 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3355e-05 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2889e-05 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2479e-05 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.2042e-05 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1665e-05 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.1283e-05 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.0920e-05 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.0567e-05 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.0206e-05 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9.9234e-06 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 9.5560e-06 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.2546e-06 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.9680e-06 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 8.6758e-06 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.4373e-06 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.1417e-06 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.8793e-06 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.6326e-06 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.3992e-06 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.1776e-06 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 6.9509e-06 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.7429e-06 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.5330e-06 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.3502e-06 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.1558e-06 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.9751e-06 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.7997e-06 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.6247e-06 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.4598e-06 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.3182e-06 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.1597e-06 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 4.9952e-06 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.8603e-06 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.7159e-06 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.5779e-06 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.4511e-06 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.3281e-06 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.2032e-06 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 4.0883e-06 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.9849e-06 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.8661e-06 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.7675e-06 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.6567e-06 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.5628e-06 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.4618e-06 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.3653e-06 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.2838e-06 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.1914e-06 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.1069e-06 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.0227e-06 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.9428e-06 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.8649e-06 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.8010e-06 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.7194e-06 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.6533e-06 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.5867e-06 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.5145e-06 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.4507e-06 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.3911e-06 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.3269e-06 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.2708e-06 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.2151e-06 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1574e-06 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.1009e-06 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.0538e-06 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.9965e-06 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.9492e-06 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.9018e-06 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8565e-06 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.8151e-06 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.7696e-06 - accuracy: 1.0000\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 30ms/step - loss: 1.7278e-06 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6834e-06 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6426e-06 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6034e-06 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5665e-06 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5298e-06 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4905e-06 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.4545e-06 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4197e-06 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3847e-06 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3551e-06 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3231e-06 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.2940e-06 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2619e-06 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2333e-06 - accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 9ms/step\n",
      "Accuracy 51.25\n",
      "Loss 4.920173168182373\n",
      "######################################### Dominance #########################################\n",
      "xtrain.shape,ytrain.shape\n",
      "(880, 32, 44, 1) (880, 2)\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 31ms/step - loss: 0.6927 - accuracy: 0.5477\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6819 - accuracy: 0.5705\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6709 - accuracy: 0.5989\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.6540 - accuracy: 0.6102\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6184 - accuracy: 0.6636\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5988 - accuracy: 0.6705\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.5617 - accuracy: 0.7045\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5072 - accuracy: 0.7625\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.4470 - accuracy: 0.8023\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.3632 - accuracy: 0.8568\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2764 - accuracy: 0.8943\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1890 - accuracy: 0.9330\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1481 - accuracy: 0.9432\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1365 - accuracy: 0.9466\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0630 - accuracy: 0.9830\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0469 - accuracy: 0.9875\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0217 - accuracy: 0.9955\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.9854e-04 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 7.8899e-04 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.0540e-04 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.3416e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.6174e-04 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.0943e-04 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.6586e-04 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 4.2507e-04 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 3.8825e-04 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 3.4944e-04 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.2552e-04 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.9168e-04 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.7808e-04 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.5083e-04 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.2893e-04 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 2.0867e-04 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.9164e-04 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.7387e-04 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6828e-04 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.5011e-04 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.3929e-04 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2405e-04 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1040e-04 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0259e-04 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.4379e-05 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.3759e-05 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 7.6735e-05 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.1616e-05 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.5963e-05 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.9505e-05 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.4282e-05 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 5.0557e-05 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.6192e-05 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.2959e-05 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9587e-05 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.6812e-05 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.4584e-05 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.2086e-05 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.9794e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 30ms/step - loss: 2.7813e-05 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.6579e-05 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.4382e-05 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.3110e-05 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.1630e-05 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.0581e-05 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.9591e-05 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.8452e-05 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.7643e-05 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.7011e-05 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.5554e-05 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.4842e-05 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 1.4060e-05 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.3568e-05 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.2782e-05 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2153e-05 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1826e-05 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.1305e-05 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.0753e-05 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.0311e-05 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.8955e-06 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 9.4311e-06 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9.0808e-06 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.7451e-06 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.3453e-06 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.1437e-06 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 7.8057e-06 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.4680e-06 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.2249e-06 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.9309e-06 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.6847e-06 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.6203e-06 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.3762e-06 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.0407e-06 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 5.7890e-06 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.5683e-06 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.3865e-06 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.1972e-06 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.0083e-06 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.8123e-06 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.6477e-06 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.5127e-06 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.3608e-06 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.2525e-06 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.0776e-06 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9508e-06 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.8450e-06 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.7041e-06 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.5978e-06 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 3.4851e-06 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.4420e-06 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.3726e-06 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.1907e-06 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.1358e-06 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.0364e-06 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.9244e-06 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.8511e-06 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.7731e-06 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.6998e-06 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.6479e-06 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.5650e-06 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.5165e-06 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.4392e-06 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.3689e-06 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.2953e-06 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.2482e-06 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.1917e-06 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.1257e-06 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.1234e-06 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.0390e-06 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.9724e-06 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.9228e-06 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8775e-06 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8294e-06 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.7963e-06 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.7487e-06 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.7109e-06 - accuracy: 1.0000\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 33ms/step - loss: 1.6616e-06 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.6268e-06 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5864e-06 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5555e-06 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.5177e-06 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4877e-06 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.4524e-06 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.4201e-06 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3863e-06 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3494e-06 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.3234e-06 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2971e-06 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2623e-06 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.2322e-06 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.2043e-06 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1817e-06 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.1569e-06 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1280e-06 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1059e-06 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.0805e-06 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0589e-06 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0401e-06 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0331e-06 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.9661e-07 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.7115e-07 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.5516e-07 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 9.3376e-07 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 9.1344e-07 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.0341e-07 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.7754e-07 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.6115e-07 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.4245e-07 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.2444e-07 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 8.0696e-07 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.9152e-07 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.7689e-07 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 7.5942e-07 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 7.4627e-07 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.2961e-07 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.1729e-07 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.0279e-07 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.8816e-07 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.7556e-07 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.6283e-07 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.4874e-07 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.3994e-07 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 6.2463e-07 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.1447e-07 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.0011e-07 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.8832e-07 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 5.7762e-07 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.6665e-07 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.6001e-07 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.4714e-07 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.3509e-07 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.2709e-07 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.1815e-07 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.0569e-07 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.9824e-07 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.9011e-07 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.8090e-07 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 4.7237e-07 - accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 12ms/step\n",
      "Accuracy 59.25\n",
      "Loss 4.451117992401123\n",
      "######################################### Liking #########################################\n",
      "xtrain.shape,ytrain.shape\n",
      "(880, 32, 44, 1) (880, 2)\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 33ms/step - loss: 0.6443 - accuracy: 0.6693\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.6245 - accuracy: 0.6830\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.6206 - accuracy: 0.6830\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.6191 - accuracy: 0.6830\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.6048 - accuracy: 0.6841\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5944 - accuracy: 0.6841\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5797 - accuracy: 0.6955\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5527 - accuracy: 0.7273\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.4987 - accuracy: 0.7591\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.4499 - accuracy: 0.7852\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.3837 - accuracy: 0.8295\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3616 - accuracy: 0.8489\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2649 - accuracy: 0.8955\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1568 - accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0962 - accuracy: 0.9739\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0960 - accuracy: 0.9659\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0376 - accuracy: 0.9932\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 0.9989\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 9.2456e-04 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.2025e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 7.3364e-04 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.4514e-04 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 5.8210e-04 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 5.3817e-04 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.7853e-04 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.4034e-04 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.1075e-04 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.7204e-04 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 3.4609e-04 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.2198e-04 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.9794e-04 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.8417e-04 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.6380e-04 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.4513e-04 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.3426e-04 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1763e-04 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 2.0528e-04 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.9374e-04 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8458e-04 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.7356e-04 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6510e-04 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5881e-04 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.4899e-04 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.4204e-04 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3542e-04 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.3031e-04 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.2336e-04 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1724e-04 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1195e-04 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0708e-04 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0260e-04 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9.8184e-05 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9.4687e-05 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 9.0593e-05 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 8.6974e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 8.3625e-05 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 8.0511e-05 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 7.7278e-05 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 7.4183e-05 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.1825e-05 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.9416e-05 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.6911e-05 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 6.4100e-05 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 6.2016e-05 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 5.9901e-05 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.7817e-05 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.5848e-05 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.4205e-05 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 5.2220e-05 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 5.0419e-05 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 4.8720e-05 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 4.7184e-05 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 4.5757e-05 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.4365e-05 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.2989e-05 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.1619e-05 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 4.0356e-05 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9132e-05 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.7965e-05 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.6815e-05 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.5743e-05 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 3.4696e-05 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.3635e-05 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.2597e-05 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.1692e-05 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 3.0896e-05 - accuracy: 1.0000\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 2.9963e-05 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.9174e-05 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.8364e-05 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.7515e-05 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.6715e-05 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.6038e-05 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.5334e-05 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.4695e-05 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.4050e-05 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.3420e-05 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.2773e-05 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.2156e-05 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1589e-05 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.1051e-05 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.0467e-05 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.9967e-05 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 1.9567e-05 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8957e-05 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.8503e-05 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.8083e-05 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.7608e-05 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.7144e-05 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6755e-05 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.6372e-05 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.5974e-05 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5631e-05 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.5215e-05 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4837e-05 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4478e-05 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.4166e-05 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.3844e-05 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.3495e-05 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3176e-05 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 1.2868e-05 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2577e-05 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2281e-05 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2017e-05 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.1755e-05 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.1458e-05 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1202e-05 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.0976e-05 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.0736e-05 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0488e-05 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.0279e-05 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0020e-05 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 9.7697e-06 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 9.5941e-06 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.3672e-06 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 9.1541e-06 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.9663e-06 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.7936e-06 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 8.5863e-06 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 8.4071e-06 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 8.2266e-06 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 8.0878e-06 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.8907e-06 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.7429e-06 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 7.5477e-06 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 7.3919e-06 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 7.2274e-06 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 7.0850e-06 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 6.9251e-06 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.8057e-06 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.6493e-06 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 6.5133e-06 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 6.3886e-06 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.2385e-06 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 6.1223e-06 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.9853e-06 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.8872e-06 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 5.7871e-06 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.6728e-06 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 5.5147e-06 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 5.4160e-06 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 5.3127e-06 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 5.1870e-06 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 5.0984e-06 - accuracy: 1.0000\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 29ms/step - loss: 4.9855e-06 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.8919e-06 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.8122e-06 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.6837e-06 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.6025e-06 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 4.5089e-06 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.4215e-06 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.3340e-06 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.2513e-06 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.1644e-06 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.0997e-06 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 4.0142e-06 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.9289e-06 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.8483e-06 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.7838e-06 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.7018e-06 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.6392e-06 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 3.5622e-06 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.4951e-06 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.4267e-06 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 3.3752e-06 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.3103e-06 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.2345e-06 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.1789e-06 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.1165e-06 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 3.0612e-06 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.9978e-06 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.9432e-06 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.8869e-06 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.8324e-06 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.7831e-06 - accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 9ms/step\n",
      "Accuracy 59.25\n",
      "Loss 3.5861423015594482\n"
     ]
    }
   ],
   "source": [
    "# Using original data\n",
    "trainlabel_list = [val22, aro22, dom22, lik22]\n",
    "testlabel_list = [y_test_va, y_test_ar, y_test_do, y_test_li]\n",
    "names = [\"Valence\",\"Arousal\",\"Dominance\",\"Liking\"]\n",
    "scorelist = []\n",
    "eps = 200 # epochs\n",
    "bs = 32 # batch size\n",
    "div = 2\n",
    "# modelnum,xtrain,ytrain,xtest,ytest,nepochs,batch_size\n",
    "\n",
    "for traain,tesst,name in zip(trainlabel_list,testlabel_list,names):\n",
    "  print(\"#########################################\",name,\"#########################################\")\n",
    "  sc = deepmodel(1,train.reshape(-1, 32,44),traain,test.reshape(-1, 32,44),tesst,nepochs=eps,batch_size=bs)\n",
    "  scorelist.append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda86b42",
   "metadata": {},
   "source": [
    "Best results <br>\n",
    "Accuracy of  Valence 51.75 <br>\n",
    "Accuracy of  Arousal 51.25 <br>\n",
    "Accuracy of  Dominance 59.25 <br>\n",
    "Accuracy of  Liking 59.25 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe5211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
