{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940c8aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "#from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D\n",
    "from denoising_diffusion_pytorch import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.stats import skew,kurtosis\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6538d09-4c52-45f2-94a3-2e2cd776574c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision numpy matplotlib einops ema_pytorch accelerate pytorch_fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea443434-8f88-4dd4-bcb2-23ab471445a6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d09d03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_testsub = 32\n",
    "num_classes = 4\n",
    "num_channel = 40\n",
    "num_datapoints = 8064\n",
    "num_trials = 40\n",
    "sampling_rate = 128 # 128Hz as given in the data\n",
    "\n",
    "def loadfiles_normalized():\n",
    "    data_dict = {}\n",
    "    print(\"Loading files into data_dict .................\")\n",
    "    for i in range(num_testsub):\n",
    "                    if i < 10:\n",
    "                        name = '%0*d' % (2,i+1)\n",
    "                    else:\n",
    "                        name = i+1\n",
    "                    fname = 'data/data_prepared/data_norm_bhat/noramlized_datasub'+str(name) +'.npy'\n",
    "                    data_dict[\"sub%s\" %name] = np.load(fname)    \n",
    "    print(\"Loaded!!!!!\") \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1d4b93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files into data_dict .................\n",
      "Loaded!!!!!\n"
     ]
    }
   ],
   "source": [
    "data = loadfiles_normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94aa7888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 99)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (40, 40, 99) (videonumber/trialnumber , channelnumber, datapoints)\n",
    "data['sub01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b10e18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 99)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix 1\n",
    "data['sub01'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f5e6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = np.zeros((880,40,104))\n",
    "matrix[:] = np.nan\n",
    "counter = 0\n",
    "for sub in data.keys():\n",
    "    if sub == 'sub23':\n",
    "        break\n",
    "    for i in range(data[sub][0].shape[0]):\n",
    "        temp = data[sub][i]\n",
    "#        print(temp.shape)\n",
    "#        temp = temp[: , :96]\n",
    "        # pad the array with a column of zeros\n",
    "        temp = np.pad(temp, ((0, 0), (0, 5)), mode='constant')\n",
    "        matrix[counter, :] = temp\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c505603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 40, 104)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e5dcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir images\n",
    "for i in range(880):\n",
    "    #transpose = np.transpose(matrix[i,:,:], (1,2,0))\n",
    "    tra = np.multiply(matrix[i,:,:], 255).astype(np.uint8)\n",
    "    img = Image.fromarray(tra)\n",
    "    img.save(\"images2/train\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7d7c6",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba4ccf",
   "metadata": {},
   "source": [
    "### PNG and JPEG comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('train20.jpeg')\n",
    "print(test.shape)\n",
    "test = np.transpose(test, (2,0,1))\n",
    "test = np.multiply(test,1/255)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = cv2.imread('train20.png')\n",
    "print(test.shape)\n",
    "test2 = np.transpose(test2, (2,0,1))\n",
    "test2 = np.multiply(test2,1/255)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(fo, test2, rtol=0.1, atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40586b5",
   "metadata": {},
   "source": [
    "For two images the png format was closer to the original input with a tolerance of 0.1 which failed in the case of jpeg. Therefore, png will be used to store the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af7beb",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf70b2a-4731-4739-a21a-f694a2f99394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from version 1.5.6\n"
     ]
    }
   ],
   "source": [
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels = 1\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = (40,104),\n",
    "    timesteps = 1000,           # number of steps\n",
    "    sampling_timesteps = 250,   # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "    loss_type = 'l2'            # L1 or L2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    'images/',\n",
    "    train_batch_size = 32,\n",
    "    train_lr = 8e-5,\n",
    "    train_num_steps = 12000,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = False,                       # turn on mixed precision\n",
    "    calculate_fid = True              # whether to calculate fid during training\n",
    ")\n",
    "#trainer.load('5')\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08e3ec20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019ae69515084c8cb01b3eaee52509c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e994a52d0c744ac86f362e7a178cad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7093d54c9314833ad32ab39cd3c2161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00454f9455fa4b24ac0f17e127dad906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfd46510bd743d39de8f8dae146ae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3c0d8376fb48419d5b061c3f55d7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89c4f359fe0412b80356b53ab87d063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be4f97c55ad4b199aa7870d2b017177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cba39ce05f4404a52c4d9d1695ac63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Sample:  9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sampled_images = diffusion.sample(batch_size = 128)\n",
    "    torch.save(sampled_images,'sampled1D_2000_128_'+str(i))\n",
    "    print(\"Finished Sample: \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3439c8-2c20-43c3-9d8e-79cc1ff15421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
