{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "htBNdHQuavJ4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 14:53:59.536268: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import skew,kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "# import autosklearn.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files into data_dict .................\n",
      "Loaded!!!!!\n"
     ]
    }
   ],
   "source": [
    "num_testsub = 32\n",
    "num_classes = 4\n",
    "num_channel = 40\n",
    "num_datapoints = 8064\n",
    "num_trials = 40\n",
    "sampling_rate = 128 # 128Hz as given in the data\n",
    "\n",
    "def loadfiles_normalized():\n",
    "    data_dict = {}\n",
    "    print(\"Loading files into data_dict .................\")\n",
    "    for i in range(num_testsub):\n",
    "                    if i < 10:\n",
    "                        name = '%0*d' % (2,i+1)\n",
    "                    else:\n",
    "                        name = i+1\n",
    "                    fname = 'data/data_prepared/data_norm_bhat/noramlized_datasub'+str(name) +'.npy'\n",
    "                    data_dict[\"sub%s\" %name] = np.load(fname)    \n",
    "    print(\"Loaded!!!!!\") \n",
    "    return data_dict\n",
    "data_dict = loadfiles_normalized()\n",
    "\n",
    "# training with 22 participants each has 40 videos = 880\n",
    "data_R = np.zeros((0,40,99))\n",
    "data_R[:] = np.nan\n",
    "\n",
    "train_R = np.zeros((0,40,99))\n",
    "train_R[:] = np.nan\n",
    "#train1 = \n",
    "test_R = np.zeros((0,40,99))\n",
    "test_R[:] = np.nan\n",
    "\n",
    "participation_counter = 0\n",
    "for sub in data_dict.keys():\n",
    "    data_R = np.concatenate((data_R, data_dict[sub]), axis=0)\n",
    "    if participation_counter < 22:\n",
    "        train_R = np.concatenate((train_R, data_dict[sub]), axis=0)\n",
    "    else:\n",
    "        test_R = np.concatenate((test_R, data_dict[sub]), axis=0)\n",
    "\n",
    "    participation_counter = participation_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 40, 99)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 40, 99)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 40, 99)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = []\n",
    "for i in range(10):\n",
    "    arrays.append(torch.load(\"data/sampled/0xx/1_sample/sampled_03_128_\"+str(i),map_location=torch.device('cpu')))\n",
    "generated_data = np.concatenate(arrays, axis=0)\n",
    "data_S = np.zeros((1280,40,99))\n",
    "data_S[:] = np.nan\n",
    "\n",
    "for i in range(1280):\n",
    "    data_S[i] = generated_data[i][0][:,:99] \n",
    "    \n",
    "train_S = data_S[:880]\n",
    "test_S = data_S[880:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = np.load('data/data_prepared/labels/label_class_0.npy')\n",
    "arousal = np.load('data/data_prepared/labels/label_class_1.npy')\n",
    "dominance = np.load('data/data_prepared/labels/label_class_2.npy')\n",
    "liking = np.load('data/data_prepared/labels/label_class_3.npy')\n",
    "\n",
    "val22 = valence[: 880]\n",
    "aro22 = arousal[: 880]\n",
    "dom22 = dominance[: 880]\n",
    "lik22 = liking[: 880]\n",
    "\n",
    "val10 = valence[880: ]\n",
    "aro10 = arousal[880: ]\n",
    "dom10 = dominance[880: ]\n",
    "lik10 = liking[880: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbApFrUYW0Cc"
   },
   "source": [
    "## K fold based "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2ehF4Q9cbkL"
   },
   "source": [
    "### Actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train R and Test R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpPlIvXG6vwP",
    "outputId": "5c1affd5-6e5e-4d06-e633-76d185a712f7"
   },
   "outputs": [],
   "source": [
    "def main_k_fold(X_R, X_S):\n",
    "    conf_matrix = 0\n",
    "    cls_report = 0\n",
    "    # This is the main K fold block \n",
    "    y = valence\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    kval = 20\n",
    "    dispresults = 0\n",
    "    nsplit = 32\n",
    "    shuffle = False\n",
    "    dispfoldres = 0\n",
    "    print()\n",
    "    print(\"################# Valence #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = arousal\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Arousal #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = dominance\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Dominance #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "\n",
    "    y = liking\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"#################Liking#################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# Valence #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 52.65625 (+- 8.476472493761777)\n",
      "------------------------------------------------------------------------\n",
      "################# Arousal #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 53.90625 (+- 9.247835473098556)\n",
      "------------------------------------------------------------------------\n",
      "################# Dominance #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 56.015625 (+- 11.351269460257518)\n",
      "------------------------------------------------------------------------\n",
      "#################Liking#################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 60.390625 (+- 10.195536994654818)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main_k_fold(data_R.reshape(32*40,40*99),data_S.reshape(32*40,40*99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train R and Test S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_k_fold(X_R, X_S):\n",
    "    conf_matrix = 0\n",
    "    cls_report = 0\n",
    "    # This is the main K fold block \n",
    "    y = valence\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    kval = 20\n",
    "    dispresults = 0\n",
    "    nsplit = 32\n",
    "    shuffle = False\n",
    "    dispfoldres = 0\n",
    "    print()\n",
    "    print(\"################# Valence #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = arousal\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Arousal #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = dominance\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Dominance #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "\n",
    "    y = liking\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"#################Liking#################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_R[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# Valence #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 47.1875 (+- 8.309209875192707)\n",
      "------------------------------------------------------------------------\n",
      "################# Arousal #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 54.6875 (+- 9.636964965693297)\n",
      "------------------------------------------------------------------------\n",
      "################# Dominance #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 51.40625 (+- 7.7039331472631565)\n",
      "------------------------------------------------------------------------\n",
      "#################Liking#################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 60.546875 (+- 8.563512143646145)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main_k_fold(data_R.reshape(32*40,40*99),data_S.reshape(32*40,40*99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Valence #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 52.65625 (+- 8.476472493761777)\n",
    "------------------------------------------------------------------------\n",
    "################# Arousal #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 53.90625 (+- 9.247835473098556)\n",
    "------------------------------------------------------------------------\n",
    "################# Dominance #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 56.015625 (+- 11.351269460257518)\n",
    "------------------------------------------------------------------------\n",
    "#################Liking#################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 60.390625 (+- 10.195536994654818)\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train S and Test R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_k_fold(X_R, X_S):\n",
    "    conf_matrix = 0\n",
    "    cls_report = 0\n",
    "    # This is the main K fold block \n",
    "    y = valence\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    kval = 20\n",
    "    dispresults = 0\n",
    "    nsplit = 32\n",
    "    shuffle = False\n",
    "    dispfoldres = 0\n",
    "    print()\n",
    "    print(\"################# Valence #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = arousal\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Arousal #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = dominance\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Dominance #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "\n",
    "    y = liking\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"#################Liking#################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_R[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# Valence #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 47.890625 (+- 6.906444425996273)\n",
      "------------------------------------------------------------------------\n",
      "################# Arousal #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 51.25 (+- 11.659223816361019)\n",
      "------------------------------------------------------------------------\n",
      "################# Dominance #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 49.84375 (+- 10.842218912081604)\n",
      "------------------------------------------------------------------------\n",
      "#################Liking#################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 64.375 (+- 12.005857945186591)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main_k_fold(data_R.reshape(32*40,40*99),data_S.reshape(32*40,40*99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train S and Test S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_k_fold(X_R, X_S):\n",
    "    conf_matrix = 0\n",
    "    cls_report = 0\n",
    "    # This is the main K fold block \n",
    "    y = valence\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    kval = 20\n",
    "    dispresults = 0\n",
    "    nsplit = 32\n",
    "    shuffle = False\n",
    "    dispfoldres = 0\n",
    "    print()\n",
    "    print(\"################# Valence #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = arousal\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Arousal #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "    y = dominance\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"################# Dominance #################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "      # ###############################################################################\n",
    "\n",
    "    y = liking\n",
    "    # Split the data into training/testing sets\n",
    "    acc_per_fold = []\n",
    "    fold_no = 1\n",
    "    print(\"#################Liking#################\")\n",
    "    kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\n",
    "    for train, test in kfold.split(X_R, y):\n",
    "      # print(X[train].shape, X[test].shape)\n",
    "      X_train = X_S[train]\n",
    "      y_train = y[train]\n",
    "      X_test = X_S[test]\n",
    "      y_test = y[test]\n",
    "\n",
    "\n",
    "      # KNN\n",
    "      clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \n",
    "      clf.fit(X_train, y_train)\n",
    "      y_predict = clf.predict(X_test)\n",
    "      acc = accuracy_score(y_test, y_predict)*100\n",
    "      acc = round(acc, 4)\n",
    "      if dispresults:\n",
    "        print(\"Accuracy score for fold\",fold_no)\n",
    "        print(acc)\n",
    "        print('\\n')\n",
    "      acc_per_fold.append(acc)\n",
    "\n",
    "      if conf_matrix:\n",
    "          print(confusion_matrix(y_test, y_predict))\n",
    "      if cls_report:\n",
    "          print(classification_report(y_test, y_predict))\n",
    "\n",
    "      fold_no = fold_no + 1\n",
    "    if dispfoldres:  \n",
    "      print('------------------------------------------------------------------------')\n",
    "      print('Score per fold')\n",
    "      for i in range(0, len(acc_per_fold)):\n",
    "          print('------------------------------------------------------------------------')\n",
    "          print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\n",
    "      print('------------------------------------------------------------------------')\n",
    "    print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################# Valence #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 50.859375 (+- 8.18748509063528)\n",
      "------------------------------------------------------------------------\n",
      "################# Arousal #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 53.984375 (+- 6.698279134178793)\n",
      "------------------------------------------------------------------------\n",
      "################# Dominance #################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 55.078125 (+- 11.206240849828948)\n",
      "------------------------------------------------------------------------\n",
      "#################Liking#################\n",
      "For K value - 20 and nsplits 32 shuffle - False\n",
      "Average scores for all folds:\n",
      "> Accuracy: 62.5 (+- 9.921567416492215)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main_k_fold(data_R.reshape(32*40,40*99),data_S.reshape(32*40,40*99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Valence #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 47.890625 (+- 6.906444425996273)\n",
    "------------------------------------------------------------------------\n",
    "################# Arousal #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 51.25 (+- 11.659223816361019)\n",
    "------------------------------------------------------------------------\n",
    "################# Dominance #################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 49.84375 (+- 10.842218912081604)\n",
    "------------------------------------------------------------------------\n",
    "#################Liking#################\n",
    "For K value - 20 and nsplits 32 shuffle - False\n",
    "Average scores for all folds:\n",
    "> Accuracy: 64.375 (+- 12.005857945186591)\n",
    "------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "submit  kfold.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
